{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51ed5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325378ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from imblearn.combine import SMOTETomek \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2aff463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Jaiprakash\\OneDrive\\Desktop\\TestProject\\SpamHamClassifier\\SpamHam.txt\", sep=\"\\t\", names=[\"Label\", \"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b5cdec",
   "metadata": {},
   "source": [
    "## Pre-processing the data\n",
    "### Some common Problems:\n",
    "- Remove Punctuation\n",
    "- Replace short words\n",
    "- Making text lower case\n",
    "- Remove stopwords\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b590925a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point  crazy   Available only ...\n",
       "1                           Ok lar    Joking wif u oni   \n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor    U c already then say   \n",
       "4       Nah I don t think he goes to usf  he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                 Will   b going to esplanade fr home \n",
       "5569    Pity    was in mood for that  So   any other s...\n",
       "5570    The guy did some bitching but I acted like i d...\n",
       "5571                           Rofl  Its true to its name\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing punctuations with space\n",
    "df[\"message\"] = df[\"messages\"].copy()\n",
    "df['message'] = df['message'].str.replace(\"[^a-zA-Z0-9]\", \" \")\n",
    "df[\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6f5707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove short words and convert words to lower case\n",
    "df[\"message\"]=df[\"message\"].apply(lambda row: \" \".join([word.lower() for word in row.split() if len(word)> 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d616464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop words\n",
    "stop_words = stopwords.words(\"english\")\n",
    "def remove_stopwords(sentence):\n",
    "    sentence_list = word_tokenize(sentence)\n",
    "    sentence_new = [word for word in sentence_list if word not in stop_words]\n",
    "    return sentence_new\n",
    "df[\"message\"] = df[\"message\"].apply(lambda row: \" \".join(remove_stopwords(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f65a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin Lemmatization \n",
    "# function to convert nltk tag to wordnet tag\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Finds the part of speech tag & Convert the detailed POS tag into a shallow information\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "# lemmatize sentence using pos tag\n",
    "def lemmatize_sentence(sentence):\n",
    "    # word tokenize -> pos tag (detailed) -> wordnet tag (shallow pos) -> lemmatizer -> \n",
    "    # root word tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "df[\"message\"] = df[\"message\"].apply(lambda row: lemmatize_sentence(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cde2414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       jurong point crazy available bugis great world...\n",
       "1                                      lar joking wif oni\n",
       "2       free entry wkly comp win cup final tkts 21st m...\n",
       "3                           dun say early hor already say\n",
       "4                     nah think go usf life around though\n",
       "                              ...                        \n",
       "5567    2nd time try contact 750 pound prize claim eas...\n",
       "5568                                    go esplanade home\n",
       "5569                                 pity mood suggestion\n",
       "5570    guy bitch act like interested buying something...\n",
       "5571                                       rofl true name\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"message\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422570fb",
   "metadata": {},
   "source": [
    "## Word Embedding:\n",
    "- Count/Frequency(OHE, BOW, TF-IDF),\n",
    "- Deep Learning trained models(Word2Vec).\n",
    "\n",
    "#### Eg: \n",
    "    - I do use this mobile. This is not good.\n",
    "    - I do not use this mobile. But heard, this is good.\n",
    "\n",
    "- In BOW and TF-IDF Approach, the semantic meaning of word is not captures.\n",
    "- Hence we can use Word2Vec model, which can capture Semanctic meaning and also reduce:\n",
    "    - Sparcity(Vectors having 1 or 0),\n",
    "    - Dimentions of Vector.\n",
    "- We can either use pretrained models like: 'word2vec-google-news-300' which converts a word into 300 dimensions.\n",
    "- Or we can train our model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e076ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "# wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "200f8c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "words = []\n",
    "for row in df[\"message\"]:\n",
    "    words.append(simple_preprocess(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a574a1",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "Eg:\n",
    "**Man, Women, King, Queen.**\n",
    "\n",
    "The Word2Vec model, converts each word into 32 or more dimensions, which gives the relationship between a word with other words, hence helps in finding the similar words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bc7763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Word2Vec Model from scratch\n",
    "import gensim\n",
    "model = gensim.models.Word2Vec(words, window=6, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ad068dc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['get',\n",
       " 'call',\n",
       " 'come',\n",
       " 'day',\n",
       " 'free',\n",
       " 'know',\n",
       " 'go',\n",
       " 'good',\n",
       " 'like',\n",
       " 'send',\n",
       " 'time',\n",
       " 'love',\n",
       " 'want',\n",
       " 'say',\n",
       " 'text',\n",
       " 'tell',\n",
       " 'take',\n",
       " 'think',\n",
       " 'need',\n",
       " 'one',\n",
       " 'see',\n",
       " 'txt',\n",
       " 'today',\n",
       " 'make',\n",
       " 'stop',\n",
       " 'home',\n",
       " 'reply',\n",
       " 'lor',\n",
       " 'sorry',\n",
       " 'still',\n",
       " 'mobile',\n",
       " 'back',\n",
       " 'dont',\n",
       " 'well',\n",
       " 'phone',\n",
       " 'week',\n",
       " 'new',\n",
       " 'please',\n",
       " 'later',\n",
       " 'pls',\n",
       " 'work',\n",
       " 'miss',\n",
       " 'give',\n",
       " 'ask',\n",
       " 'dear',\n",
       " 'msg',\n",
       " 'message',\n",
       " 'night',\n",
       " 'wait',\n",
       " 'thing',\n",
       " 'try',\n",
       " 'great',\n",
       " 'much',\n",
       " 'hope',\n",
       " 'claim',\n",
       " 'leave',\n",
       " 'hey',\n",
       " 'number',\n",
       " 'min',\n",
       " 'happy',\n",
       " 'meet',\n",
       " 'wat',\n",
       " 'way',\n",
       " 'yes',\n",
       " 'www',\n",
       " 'find',\n",
       " 'friend',\n",
       " 'late',\n",
       " 'let',\n",
       " 'na',\n",
       " 'prize',\n",
       " 'wan',\n",
       " 'right',\n",
       " 'win',\n",
       " 'tomorrow',\n",
       " 'already',\n",
       " 'pick',\n",
       " 'cash',\n",
       " 'amp',\n",
       " 'life',\n",
       " 'yeah',\n",
       " 'really',\n",
       " 'feel',\n",
       " 'tone',\n",
       " 'babe',\n",
       " 'keep',\n",
       " 'sleep',\n",
       " 'care',\n",
       " 'morning',\n",
       " 'last',\n",
       " 'even',\n",
       " 'service',\n",
       " 'thanks',\n",
       " 'buy',\n",
       " 'anything',\n",
       " 'com',\n",
       " 'would',\n",
       " 'contact',\n",
       " 'year',\n",
       " 'start',\n",
       " 'use',\n",
       " 'lol',\n",
       " 'also',\n",
       " 'nokia',\n",
       " 'every',\n",
       " 'look',\n",
       " 'wish',\n",
       " 'sure',\n",
       " 'urgent',\n",
       " 'end',\n",
       " 'show',\n",
       " 'something',\n",
       " 'smile',\n",
       " 'award',\n",
       " 'watch',\n",
       " 'gud',\n",
       " 'place',\n",
       " 'cant',\n",
       " 'finish',\n",
       " 'first',\n",
       " 'box',\n",
       " 'help',\n",
       " 'someone',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'tonight',\n",
       " 'chat',\n",
       " 'guy',\n",
       " 'around',\n",
       " 'talk',\n",
       " 'word',\n",
       " 'soon',\n",
       " 'money',\n",
       " 'could',\n",
       " 'customer',\n",
       " 'per',\n",
       " 'many',\n",
       " 'gon',\n",
       " 'name',\n",
       " 'always',\n",
       " 'plan',\n",
       " 'dun',\n",
       " 'lot',\n",
       " 'special',\n",
       " 'co',\n",
       " 'hello',\n",
       " 'fine',\n",
       " 'person',\n",
       " 'live',\n",
       " 'check',\n",
       " 'girl',\n",
       " 'mean',\n",
       " 'may',\n",
       " 'best',\n",
       " 'heart',\n",
       " 'minute',\n",
       " 'haha',\n",
       " 'people',\n",
       " 'hour',\n",
       " 'thk',\n",
       " 'do',\n",
       " 'yet',\n",
       " 'reach',\n",
       " 'month',\n",
       " 'offer',\n",
       " 'ppm',\n",
       " 'god',\n",
       " 'stuff',\n",
       " 'cost',\n",
       " 'happen',\n",
       " 'pay',\n",
       " 'class',\n",
       " 'play',\n",
       " 'eat',\n",
       " 'line',\n",
       " 'holiday',\n",
       " 'receive',\n",
       " 'fuck',\n",
       " 'lunch',\n",
       " 'man',\n",
       " 'car',\n",
       " 'job',\n",
       " 'draw',\n",
       " 'enjoy',\n",
       " 'long',\n",
       " 'big',\n",
       " 'never',\n",
       " 'problem',\n",
       " 'cool',\n",
       " 'thats',\n",
       " 'bit',\n",
       " 'yup',\n",
       " 'ill',\n",
       " 'drive',\n",
       " 'account',\n",
       " 'mind',\n",
       " 'house',\n",
       " 'st',\n",
       " 'date',\n",
       " 'rate',\n",
       " 'pobox',\n",
       " 'dat',\n",
       " 'speak',\n",
       " 'ready',\n",
       " 'chance',\n",
       " 'forget',\n",
       " 'sweet',\n",
       " 'weekend',\n",
       " 'guess',\n",
       " 'lose',\n",
       " 'worry',\n",
       " 'game',\n",
       " 'world',\n",
       " 'real',\n",
       " 'guarantee',\n",
       " 'half',\n",
       " 'room',\n",
       " 'sir',\n",
       " 'sm',\n",
       " 'book',\n",
       " 'luv',\n",
       " 'camera',\n",
       " 'sit',\n",
       " 'voucher',\n",
       " 'pic',\n",
       " 'nothing',\n",
       " 'lar',\n",
       " 'early',\n",
       " 'shit',\n",
       " 'bad',\n",
       " 'bring',\n",
       " 'question',\n",
       " 'another',\n",
       " 'charge',\n",
       " 'liao',\n",
       " 'run',\n",
       " 'put',\n",
       " 'age',\n",
       " 'landline',\n",
       " 'join',\n",
       " 'kiss',\n",
       " 'pm',\n",
       " 'xxx',\n",
       " 'dinner',\n",
       " 'birthday',\n",
       " 'th',\n",
       " 'easy',\n",
       " 'wake',\n",
       " 'stay',\n",
       " 'remember',\n",
       " 'hear',\n",
       " 'ever',\n",
       " 'boy',\n",
       " 'quite',\n",
       " 'jus',\n",
       " 'might',\n",
       " 'video',\n",
       " 'collect',\n",
       " 'network',\n",
       " 'wont',\n",
       " 'apply',\n",
       " 'two',\n",
       " 'aight',\n",
       " 'orange',\n",
       " 'change',\n",
       " 'thanx',\n",
       " 'hurt',\n",
       " 'baby',\n",
       " 'bed',\n",
       " 'dream',\n",
       " 'probably',\n",
       " 'point',\n",
       " 'fun',\n",
       " 'den',\n",
       " 'bus',\n",
       " 'nite',\n",
       " 'maybe',\n",
       " 'part',\n",
       " 'princess',\n",
       " 'ringtone',\n",
       " 'shop',\n",
       " 'shall',\n",
       " 'actually',\n",
       " 'sent',\n",
       " 'office',\n",
       " 'answer',\n",
       " 'gift',\n",
       " 'select',\n",
       " 'meeting',\n",
       " 'dunno',\n",
       " 'code',\n",
       " 'sound',\n",
       " 'leh',\n",
       " 'dis',\n",
       " 'anyway',\n",
       " 'true',\n",
       " 'wife',\n",
       " 'mail',\n",
       " 'little',\n",
       " 'hrs',\n",
       " 'nd',\n",
       " 'didnt',\n",
       " 'everything',\n",
       " 'face',\n",
       " 'walk',\n",
       " 'enough',\n",
       " 'movie',\n",
       " 'school',\n",
       " 'pound',\n",
       " 'dad',\n",
       " 'town',\n",
       " 'thank',\n",
       " 'afternoon',\n",
       " 'without',\n",
       " 'tmr',\n",
       " 'entry',\n",
       " 'pain',\n",
       " 'post',\n",
       " 'sexy',\n",
       " 'detail',\n",
       " 'important',\n",
       " 'price',\n",
       " 'xmas',\n",
       " 'must',\n",
       " 'valid',\n",
       " 'okay',\n",
       " 'wif',\n",
       " 'hav',\n",
       " 'test',\n",
       " 'mate',\n",
       " 'since',\n",
       " 'though',\n",
       " 'credit',\n",
       " 'abt',\n",
       " 'drink',\n",
       " 'wot',\n",
       " 'smoke',\n",
       " 'til',\n",
       " 'decide',\n",
       " 'mob',\n",
       " 'collection',\n",
       " 'update',\n",
       " 'able',\n",
       " 'close',\n",
       " 'juz',\n",
       " 'decimal',\n",
       " 'order',\n",
       " 'wen',\n",
       " 'away',\n",
       " 'lesson',\n",
       " 'plus',\n",
       " 'colour',\n",
       " 'plz',\n",
       " 'double',\n",
       " 'weekly',\n",
       " 'saw',\n",
       " 'hair',\n",
       " 'till',\n",
       " 'music',\n",
       " 'top',\n",
       " 'alright',\n",
       " 'attempt',\n",
       " 'havent',\n",
       " 'yesterday',\n",
       " 'drop',\n",
       " 'hold',\n",
       " 'dude',\n",
       " 'enter',\n",
       " 'else',\n",
       " 'hand',\n",
       " 'net',\n",
       " 'goin',\n",
       " 'trip',\n",
       " 'food',\n",
       " 'haf',\n",
       " 'optout',\n",
       " 'cos',\n",
       " 'break',\n",
       " 'online',\n",
       " 'await',\n",
       " 'coz',\n",
       " 'head',\n",
       " 'oso',\n",
       " 'lei',\n",
       " 'shopping',\n",
       " 'hot',\n",
       " 'wonder',\n",
       " 'ring',\n",
       " 'friendship',\n",
       " 'address',\n",
       " 'read',\n",
       " 'invite',\n",
       " 'ard',\n",
       " 'player',\n",
       " 'family',\n",
       " 'gr',\n",
       " 'club',\n",
       " 'set',\n",
       " 'national',\n",
       " 'search',\n",
       " 'delivery',\n",
       " 'either',\n",
       " 'sch',\n",
       " 'wid',\n",
       " 'second',\n",
       " 'together',\n",
       " 'bonus',\n",
       " 'http',\n",
       " 'beautiful',\n",
       " 'sad',\n",
       " 'sae',\n",
       " 'tot',\n",
       " 'choose',\n",
       " 'believe',\n",
       " 'cause',\n",
       " 'brother',\n",
       " 'story',\n",
       " 'bore',\n",
       " 'touch',\n",
       " 'busy',\n",
       " 'full',\n",
       " 'huh',\n",
       " 'mins',\n",
       " 'study',\n",
       " 'eve',\n",
       " 'info',\n",
       " 'match',\n",
       " 'chikku',\n",
       " 'land',\n",
       " 'poly',\n",
       " 'die',\n",
       " 'old',\n",
       " 'noe',\n",
       " 'email',\n",
       " 'row',\n",
       " 'mom',\n",
       " 'wil',\n",
       " 'parent',\n",
       " 'awesome',\n",
       " 'mum',\n",
       " 'treat',\n",
       " 'content',\n",
       " 'simple',\n",
       " 'listen',\n",
       " 'news',\n",
       " 'okie',\n",
       " 'congrats',\n",
       " 'tomo',\n",
       " 'rite',\n",
       " 'pub',\n",
       " 'private',\n",
       " 'aft',\n",
       " 'mths',\n",
       " 'sms',\n",
       " 'suite',\n",
       " 'open',\n",
       " 'sister',\n",
       " 'tho',\n",
       " 'available',\n",
       " 'company',\n",
       " 'move',\n",
       " 'value',\n",
       " 'sort',\n",
       " 'anyone',\n",
       " 'valentine',\n",
       " 'opt',\n",
       " 'fast',\n",
       " 'hop',\n",
       " 'final',\n",
       " 'spend',\n",
       " 'everyone',\n",
       " 'reveal',\n",
       " 'neva',\n",
       " 'auction',\n",
       " 'fancy',\n",
       " 'caller',\n",
       " 'angry',\n",
       " 'mine',\n",
       " 'am',\n",
       " 'unsubscribe',\n",
       " 'card',\n",
       " 'reason',\n",
       " 'statement',\n",
       " 'ticket',\n",
       " 'understand',\n",
       " 'bank',\n",
       " 'whatever',\n",
       " 'knw',\n",
       " 'lucky',\n",
       " 'laugh',\n",
       " 'visit',\n",
       " 'alone',\n",
       " 'gal',\n",
       " 'seem',\n",
       " 'si',\n",
       " 'sun',\n",
       " 'carlos',\n",
       " 'type',\n",
       " 'worth',\n",
       " 'whats',\n",
       " 'mobileupd',\n",
       " 'college',\n",
       " 'boytoy',\n",
       " 'saturday',\n",
       " 'park',\n",
       " 'log',\n",
       " 'add',\n",
       " 'sell',\n",
       " 'forward',\n",
       " 'anytime',\n",
       " 'prob',\n",
       " 'frnd',\n",
       " 'dog',\n",
       " 'hit',\n",
       " 'ltd',\n",
       " 'ni',\n",
       " 'smth',\n",
       " 'congratulation',\n",
       " 'hows',\n",
       " 'kind',\n",
       " 'secret',\n",
       " 'friday',\n",
       " 'bout',\n",
       " 'party',\n",
       " 'welcome',\n",
       " 'crazy',\n",
       " 'identifier',\n",
       " 'quiz',\n",
       " 'expires',\n",
       " 'surprise',\n",
       " 'gbp',\n",
       " 'winner',\n",
       " 'far',\n",
       " 'nyt',\n",
       " 'wonderful',\n",
       " 'hard',\n",
       " 'song',\n",
       " 'cut',\n",
       " 'evening',\n",
       " 'darlin',\n",
       " 'save',\n",
       " 'goodmorning',\n",
       " 'bill',\n",
       " 'chennai',\n",
       " 'camcorder',\n",
       " 'outside',\n",
       " 'tel',\n",
       " 'case',\n",
       " 'light',\n",
       " 'download',\n",
       " 'finally',\n",
       " 'oredi',\n",
       " 'lovely',\n",
       " 'lands',\n",
       " 'follow',\n",
       " 'return',\n",
       " 'mrng',\n",
       " 'nope',\n",
       " 'fri',\n",
       " 'rain',\n",
       " 'wit',\n",
       " 'least',\n",
       " 'drug',\n",
       " 'confirm',\n",
       " 'pretty',\n",
       " 'sea',\n",
       " 'operator',\n",
       " 'uncle',\n",
       " 'wrong',\n",
       " 'project',\n",
       " 'suppose',\n",
       " 'whole',\n",
       " 'exam',\n",
       " 'frnds',\n",
       " 'term',\n",
       " 'cum',\n",
       " 'catch',\n",
       " 'blue',\n",
       " 'freemsg',\n",
       " 'scream',\n",
       " 'hungry',\n",
       " 'cheap',\n",
       " 'jay',\n",
       " 'rock',\n",
       " 'fone',\n",
       " 'wq',\n",
       " 'hmm',\n",
       " 'kid',\n",
       " 'joke',\n",
       " 'fix',\n",
       " 'sunday',\n",
       " 'ten',\n",
       " 'snow',\n",
       " 'sub',\n",
       " 'support',\n",
       " 'wkly',\n",
       " 'course',\n",
       " 'unlimited',\n",
       " 'bath',\n",
       " 'savamob',\n",
       " 'thought',\n",
       " 'frm',\n",
       " 'yar',\n",
       " 'felt',\n",
       " 'christmas',\n",
       " 'couple',\n",
       " 'john',\n",
       " 'shower',\n",
       " 'motorola',\n",
       " 'etc',\n",
       " 'side',\n",
       " 'slow',\n",
       " 'within',\n",
       " 'figure',\n",
       " 'area',\n",
       " 'father',\n",
       " 'bslvyl',\n",
       " 'press',\n",
       " 'sk',\n",
       " 'stupid',\n",
       " 'mayb',\n",
       " 'currently',\n",
       " 'happiness',\n",
       " 'india',\n",
       " 'joy',\n",
       " 'hee',\n",
       " 'film',\n",
       " 'murder',\n",
       " 'fight',\n",
       " 'paper',\n",
       " 'computer',\n",
       " 'balance',\n",
       " 'almost',\n",
       " 'ago',\n",
       " 'single',\n",
       " 'promise',\n",
       " 'moment',\n",
       " 'gas',\n",
       " 'dnt',\n",
       " 'hmmm',\n",
       " 'child',\n",
       " 'march',\n",
       " 'turn',\n",
       " 'sex',\n",
       " 'store',\n",
       " 'luck',\n",
       " 'mah',\n",
       " 'hl',\n",
       " 'txts',\n",
       " 'rental',\n",
       " 'comp',\n",
       " 'doin',\n",
       " 'via',\n",
       " 'fill',\n",
       " 'swing',\n",
       " 'xx',\n",
       " 'ish',\n",
       " 'small',\n",
       " 'difficult',\n",
       " 'max',\n",
       " 'rent',\n",
       " 'ta',\n",
       " 'ipod',\n",
       " 'stand',\n",
       " 'clean',\n",
       " 'deal',\n",
       " 'cheer',\n",
       " 'fall',\n",
       " 'grin',\n",
       " 'hospital',\n",
       " 'askd',\n",
       " 'darren',\n",
       " 'train',\n",
       " 'write',\n",
       " 'gym',\n",
       " 'direct',\n",
       " 'laptop',\n",
       " 'information',\n",
       " 'crave',\n",
       " 'eye',\n",
       " 'reward',\n",
       " 'wow',\n",
       " 'remove',\n",
       " 'semester',\n",
       " 'told',\n",
       " 'correct',\n",
       " 'bcoz',\n",
       " 'teach',\n",
       " 'red',\n",
       " 'pas',\n",
       " 'extra',\n",
       " 'short',\n",
       " 'ugh',\n",
       " 'complimentary',\n",
       " 'fact',\n",
       " 'din',\n",
       " 'somebody',\n",
       " 'std',\n",
       " 'fantasy',\n",
       " 'noon',\n",
       " 'comin',\n",
       " 'police',\n",
       " 'convey',\n",
       " 'slowly',\n",
       " 'weed',\n",
       " 'abiola',\n",
       " 'page',\n",
       " 'discount',\n",
       " 'idea',\n",
       " 'loan',\n",
       " 'rest',\n",
       " 'guaranteed',\n",
       " 'asap',\n",
       " 'nobody',\n",
       " 'include',\n",
       " 'whenever',\n",
       " 'rply',\n",
       " 'pete',\n",
       " 'door',\n",
       " 'txting',\n",
       " 'usf',\n",
       " 'redeemed',\n",
       " 'wana',\n",
       " 'member',\n",
       " 'truth',\n",
       " 'lovable',\n",
       " 'disturb',\n",
       " 'less',\n",
       " 'complete',\n",
       " 'orchard',\n",
       " 'lover',\n",
       " 'expect',\n",
       " 'request',\n",
       " 'deep',\n",
       " 'kate',\n",
       " 'monday',\n",
       " 'tire',\n",
       " 'road',\n",
       " 'copy',\n",
       " 'lady',\n",
       " 'muz',\n",
       " 'wine',\n",
       " 'safe',\n",
       " 'hmv',\n",
       " 'yep',\n",
       " 'warm',\n",
       " 'as',\n",
       " 'blood',\n",
       " 'link',\n",
       " 'photo',\n",
       " 'wap',\n",
       " 'share',\n",
       " 'pray',\n",
       " 'summer',\n",
       " 'rakhesh',\n",
       " 'heard',\n",
       " 'near',\n",
       " 'cover',\n",
       " 'ringtones',\n",
       " 'ldn',\n",
       " 'wc',\n",
       " 'gettin',\n",
       " 'bag',\n",
       " 'style',\n",
       " 'getzed',\n",
       " 'different',\n",
       " 'water',\n",
       " 'regard',\n",
       " 'across',\n",
       " 'no',\n",
       " 'cancel',\n",
       " 'mistake',\n",
       " 'king',\n",
       " 'ntt',\n",
       " 'an',\n",
       " 'gap',\n",
       " 'sale',\n",
       " 'fantastic',\n",
       " 'poor',\n",
       " 'earlier',\n",
       " 'sat',\n",
       " 'energy',\n",
       " 'glad',\n",
       " 'doctor',\n",
       " 'voice',\n",
       " 'opinion',\n",
       " 'otherwise',\n",
       " 'register',\n",
       " 'usual',\n",
       " 'load',\n",
       " 'del',\n",
       " 'sign',\n",
       " 'normal',\n",
       " 'street',\n",
       " 'med',\n",
       " 'tonite',\n",
       " 'oops',\n",
       " 'forgot',\n",
       " 'kick',\n",
       " 'merry',\n",
       " 'men',\n",
       " 'somewhere',\n",
       " 'england',\n",
       " 'sony',\n",
       " 'quote',\n",
       " 'custcare',\n",
       " 'bathe',\n",
       " 'admirer',\n",
       " 'immediately',\n",
       " 'trust',\n",
       " 'excuse',\n",
       " 'representative',\n",
       " 'callertune',\n",
       " 'situation',\n",
       " 'forever',\n",
       " 'nah',\n",
       " 'cup',\n",
       " 'empty',\n",
       " 'goodnight',\n",
       " 'kinda',\n",
       " 'meant',\n",
       " 'lect',\n",
       " 'specially',\n",
       " 'tht',\n",
       " 'ldew',\n",
       " 'tough',\n",
       " 'marry',\n",
       " 'thinkin',\n",
       " 'flight',\n",
       " 'coffee',\n",
       " 'bold',\n",
       " 'others',\n",
       " 'mode',\n",
       " 'result',\n",
       " 'lazy',\n",
       " 'indian',\n",
       " 'completely',\n",
       " 'dead',\n",
       " 'silent',\n",
       " 'sofa',\n",
       " 'mrt',\n",
       " 'colleague',\n",
       " 'especially',\n",
       " 'lift',\n",
       " 'ive',\n",
       " 'doesnt',\n",
       " 'tear',\n",
       " 'waste',\n",
       " 'fat',\n",
       " 'flirt',\n",
       " 'meh',\n",
       " 'self',\n",
       " 'hotel',\n",
       " 'hurry',\n",
       " 'moral',\n",
       " 'appreciate',\n",
       " 'become',\n",
       " 'flag',\n",
       " 'round',\n",
       " 'possible',\n",
       " 'sunshine',\n",
       " 'excellent',\n",
       " 'password',\n",
       " 'mon',\n",
       " 'norm',\n",
       " 'ice',\n",
       " 'bid',\n",
       " 'gay',\n",
       " 'comuk',\n",
       " 'deliver',\n",
       " 'charity',\n",
       " 'sick',\n",
       " 'unless',\n",
       " 'rise',\n",
       " 'wed',\n",
       " 'cr',\n",
       " 'tampa',\n",
       " 'bluetooth',\n",
       " 'list',\n",
       " 'accept',\n",
       " 'sport',\n",
       " 'user',\n",
       " 'iam',\n",
       " 'reference',\n",
       " 'cake',\n",
       " 'none',\n",
       " 'urself',\n",
       " 'rcvd',\n",
       " 'seriously',\n",
       " 'hiya',\n",
       " 'access',\n",
       " 'feeling',\n",
       " 'digital',\n",
       " 'cook',\n",
       " 'record',\n",
       " 'sometimes',\n",
       " 'workin',\n",
       " 'daddy',\n",
       " 'quick',\n",
       " 'process',\n",
       " 'swt',\n",
       " 'travel',\n",
       " 'miracle',\n",
       " 'anymore',\n",
       " 'freephone',\n",
       " 'remind',\n",
       " 'pizza',\n",
       " 'goto',\n",
       " 'issue',\n",
       " 'medical',\n",
       " 'black',\n",
       " 'cute',\n",
       " 'team',\n",
       " 'finger',\n",
       " 'mark',\n",
       " 'friends',\n",
       " 'learn',\n",
       " 'lay',\n",
       " 'tuesday',\n",
       " 'weight',\n",
       " 'umma',\n",
       " 'bx',\n",
       " 'bedroom',\n",
       " 'ave',\n",
       " 'ip',\n",
       " 'omg',\n",
       " 'slave',\n",
       " 'we',\n",
       " 'student',\n",
       " 'however',\n",
       " 'space',\n",
       " 'trouble',\n",
       " 'library',\n",
       " 'apartment',\n",
       " 'cinema',\n",
       " 'inc',\n",
       " 'letter',\n",
       " 'dvd',\n",
       " 'roommate',\n",
       " 'yrs',\n",
       " 'honey',\n",
       " 'bak',\n",
       " 'present',\n",
       " 'nigeria',\n",
       " 'frens',\n",
       " 'bother',\n",
       " 'euro',\n",
       " 'polys',\n",
       " 'future',\n",
       " 'moon',\n",
       " 'alex',\n",
       " 'mp',\n",
       " 'interested',\n",
       " 'lem',\n",
       " 'pix',\n",
       " 'aha',\n",
       " 'inside',\n",
       " 'horny',\n",
       " 'power',\n",
       " 'file',\n",
       " 'fullonsms',\n",
       " 'arrive',\n",
       " 'wx',\n",
       " 'thru',\n",
       " 'facebook',\n",
       " 'high',\n",
       " 'picture',\n",
       " 'throw',\n",
       " 'star',\n",
       " 'wednesday',\n",
       " 'ppmx',\n",
       " 'yahoo',\n",
       " 'realy',\n",
       " 'funny',\n",
       " 'mood',\n",
       " 'fault',\n",
       " 'woman',\n",
       " 'wiv',\n",
       " 'south',\n",
       " 'respond',\n",
       " 'sense',\n",
       " 'instead',\n",
       " 'lac',\n",
       " 'model',\n",
       " 'hr',\n",
       " 'cuz',\n",
       " 'thnk',\n",
       " 'alrite',\n",
       " 'sing',\n",
       " 'definitely',\n",
       " 'damn',\n",
       " 'location',\n",
       " 'sol',\n",
       " 'quality',\n",
       " 'awake',\n",
       " 'wun',\n",
       " 'dey',\n",
       " 'hug',\n",
       " 'mad',\n",
       " 'tat',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5310c867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42595a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a09ed09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('day', 0.9994715452194214),\n",
       " ('good', 0.9994264841079712),\n",
       " ('love', 0.9993661046028137),\n",
       " ('dear', 0.9993555545806885),\n",
       " ('friend', 0.9993463754653931),\n",
       " ('hope', 0.9993451237678528),\n",
       " ('even', 0.999329149723053),\n",
       " ('heart', 0.9993277788162231),\n",
       " ('wish', 0.9993218183517456),\n",
       " ('one', 0.999321460723877)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word(\"happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a10d0e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"night\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aae8a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec(doc):  \n",
    "    return np.mean([model.wv[word] for word in doc if word in model.wv.index_to_key],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13613b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\jaiprakash\\anaconda3\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaiprakash\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7426eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lar', 'joking', 'wif', 'oni']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0827ba3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/5572 [00:00<?, ?it/s]C:\\Users\\Jaiprakash\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Jaiprakash\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 5572/5572 [00:00<00:00, 12383.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "X=[]\n",
    "for i in tqdm(range(len(words))):\n",
    "    X.append(avg_word2vec(words[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65ed5b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Label.map({'spam' : 1, 'ham' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61c8bc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cash', 0.9993554949760437),\n",
       " ('reply', 0.9993322491645813),\n",
       " ('txt', 0.9993255138397217),\n",
       " ('box', 0.9993114471435547),\n",
       " ('send', 0.9992994070053101),\n",
       " ('holiday', 0.9992895722389221),\n",
       " ('text', 0.999282956123352),\n",
       " ('www', 0.9992719292640686),\n",
       " ('call', 0.9992600679397583),\n",
       " ('msg', 0.999239444732666)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word(\"price\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
